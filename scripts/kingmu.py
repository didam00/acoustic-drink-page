# ğŸ“¦ Namuwiki ABV Extractor (Streaming + Status Output)
# Requires: datasets, pandas
# pip install datasets pandas

from datasets import load_dataset
import re
import json
import pandas as pd
from tqdm import tqdm

# ğŸ”¹ Load local ingredients list
with open("ingredients_with_syn_array.json", "r", encoding="utf-8") as f:
    ingredient_list = json.load(f)

# ğŸ”¹ Search targets: name + synonyms
search_terms = set()
for item in ingredient_list:
    search_terms.add(item["name"])
    search_terms.update(item["syn"])

# ğŸ”¹ Regex for extracting ABV
abv_pattern = re.compile(r"(ë„ìˆ˜|ì•Œì½”ì˜¬\s*ë„ìˆ˜)\s*[:\-]?\s*(ì•½\s*)?(\d{1,2}(?:\.\d+)?)(\s*[%í¼ì„¼íŠ¸])?", re.IGNORECASE)

# ğŸ”¹ Load namuwiki dataset in streaming mode (RAM-efficient)
dataset = load_dataset("heegyu/namuwiki", split="train", streaming=True)

# ğŸ”¹ Process and collect ABV info
extracted_abvs = {}
progress_bar = tqdm(dataset, desc="Searching Namuwiki", unit="entry")

for entry in progress_bar:
    title = entry["title"]
    if title in search_terms:
        matches = abv_pattern.findall(entry["text"])
        if matches:
            values = [float(m[2]) for m in matches]
            extracted_abvs[title] = max(values)
            progress_bar.set_postfix(found=title)

# ğŸ”¹ Merge into original list
final_data = []
for item in ingredient_list:
    candidates = [item["name"]] + item["syn"]
    abv = next((extracted_abvs.get(name) for name in candidates if name in extracted_abvs), item.get("abv", 0))
    final_data.append({
        "name": item["name"],
        "syn": item["syn"],
        "category": item["category"],
        "abv": abv if abv is not None else 0
    })

# ğŸ”¹ Save result
with open("ingredients_enriched_with_namuwiki_abv.json", "w", encoding="utf-8") as f:
    json.dump(final_data, f, ensure_ascii=False, indent=2)

pd.DataFrame(final_data).to_csv("ingredients_enriched_with_namuwiki_abv.csv", index=False, encoding="utf-8")

print("âœ… ë„ìˆ˜ ì •ë³´ ë³‘í•© ì™„ë£Œ! 'ingredients_enriched_with_namuwiki_abv.*' íŒŒì¼ì„ í™•ì¸í•˜ì„¸ìš”.")
